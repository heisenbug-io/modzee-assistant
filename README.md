# ğŸ¤– Modzee AI-Powered Assistant

This is a full-stack AI assistant module for **Modzee**, built using **Vue 3** (frontend) and **Laravel 12** (backend).  
It uses the **Google Gemini API** to answer user prompts, analyze structured JSON data, and simulate multi-turn conversations.

---

## âœ¨ Features

- ğŸ”— Gemini API integration (secure via `.env`)
- ğŸ’¬ AI-powered Chat Assistant with history
- ğŸ“Š Bonus: Detects and summarizes JSON datasets
- ğŸ§  Multi-turn conversation memory using DB
- ğŸ¨ Clean modern UI built with TailwindCSS
- âš¡ Auto-expanding chat input (like ChatGPT)
- ğŸ“„ Markdown-formatted AI responses

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: Vue 3 + Vite + TailwindCSS
- **Backend**: Laravel 12 (API only)
- **AI**: Google Gemini API (v1beta)
- **Database**: SQLite (via Laravel Eloquent)
- **Styling**: TailwindCSS + `marked` for Markdown parsing

---

## ğŸš€ Quick Start

### 1. Clone the Repo

```bash
git clone https://github.com/heisenbug-io/modzee-assistant.git
cd modzee-assistant
```

---

### 2. Backend Setup (Laravel 12)

```bash
cd backend
composer install
cp .env.example .env
php artisan key:generate
```

#### Set your Google API key in `.env`:
```
GEMINI_API_KEY=your_actual_gemini_api_key
```

```bash
php artisan migrate
php artisan serve
```

âœ… This runs your Laravel API at [http://localhost:8000](http://localhost:8000)

---

### 3. Frontend Setup (Vue 3)

```bash
cd ../frontend
npm install
npm run dev
```

âœ… This runs your frontend app at [http://localhost:5173](http://localhost:5173)

---

## ğŸ“¡ API Endpoints

| Method | Endpoint                   | Description                       |
|--------|----------------------------|-----------------------------------|
| POST   | `/api/ai/assistant`        | Send a user prompt to Gemini      |
| GET    | `/api/ai/logs`             | Fetch chat history                |
| POST   | `/api/ai/reset`            | Clear chat conversation history   |

---

## ğŸ¤“ How It Works

- Each user message is stored in the `ai_logs` table
- All prior messages are sent with every new prompt
- JSON data in prompt? â¡ï¸ Automatically formatted for Gemini summarization
- Gemini replies are markdown-formatted and rendered beautifully in the UI

---

## ğŸ”’ Security Notes

- API key is stored in `.env` and never exposed on the frontend
- CORS is configured for local development (`localhost:5173`)
- Only the backend calls Gemini via `Http::withHeaders()`

---

## ğŸ§  Credits

Built with â¤ï¸ by Pujan Bhuva (@heisenbug-io) as part of an AI integration skills test for Modzee.

---

## ğŸ“„ License

MIT License
